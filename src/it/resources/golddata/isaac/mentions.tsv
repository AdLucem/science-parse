15aa277b1054cdcdf7fc018e3a3abe2df7a1691b	Predictive representations of state are a class of generative models that represent a dynamical system in terms of a set of predictions about sequences of observations generated by that system (Littman et al., 2002).|Littman et al., 2002	There is a large body of recent work on basis function selection and construction for value function approximation in Markov decision processes (Mahadevan, 2008; Parr et al., 2007), and it may be interesting to consider applying work in those areas to choosing or constructing appropriate features for observation spaces in partially observable, continuous domains.|Mahadevan, 2008	An online discovery algorithm for discrete TD networks was presented in Makino and Tagaki (2008).|Makino and Tagaki 2008	There is a large body of recent work on basis function selection and construction for value function approximation in Markov decision processes (Mahadevan, 2008; Parr et al., 2007), and it may be interesting to consider applying work in those areas to choosing or constructing appropriate features for observation spaces in partially observable, continuous domains.|Parr et al., 2007	Empirically it has also been shown that in certain domains predictive representations can lead to better generalization than other representations (Rafols et al., 2005).|Rafols et al., 2005	Recent work has shown that certain formalizations of predictive representations are strictly more expressive than other models of discrete dynamical systems that use historical information or probabilistic distributions over unobservable variables as a representation (e.g., k-Markov models, POMDPs) (Singh & James, 2004).|Singh & James,  2004	Eligibility traces were originally introduced in Sutton (1988) to provide a mechanism for making more general n-step backups of predictions in conventional TD learning, rather than the traditional 1-step backups.|Sutton 1988	Predictions of the values of these functions, which together define state, can then be used as features for approximating other functions, e.g, value functions in a reinforcement learning setting (Sutton & Barto, 1998).|Sutton & Barto, 1998	We refer the reader to Sutton and Barto (1998) for the details of the dynamics.|Sutton and Barto 1998	However, although temporal abstraction in discrete TD networks has been explored recently (Sutton et al., 2006), to our knowledge there has been no work on state abstraction in TD networks.|Sutton et al., 2006	One formalism for predictive representations is the Temporal-difference (TD) network (Sutton & Tanner, 2005).|Sutton & Tanner, 2005	Tanner and Sutton (2005) introduced TD(λ) networks, which incorporate eligibility traces to deal with certain shortcomings of conventional TD networks.|Tanner and Sutton 2005	We have only presented essential notation and intuition here, and refer the reader to Tanner and Sutton (2005) for the full details of the algorithm. In the following section we present our modified TD(λ) algorithm, which allows for continuous observations and actions.|Tanner and Sutton 2005	Modified from Tanner and Sutton (2005).|Tanner and Sutton 2005	The algorithm is modified from Tanner and Sutton (2005).|Tanner  and  Sutton 2005	This structure is similar to previous question network structures used in some discrete TD networks (Tanner & Sutton, 2005).|Tanner & Sutton, 2005	This is essentially a noisy, continuous analog of the cycle world presented in Tanner and Sutton (2005).|Tanner and Sutton 2005	We see that the network is able to learn a good model even given noisy observations with an amount of experience roughly equivalent to the amount taken to learn the deterministic, discrete version of this problem, as presented in Tanner and Sutton (2005).|Tanner and Sutton 2005	Although there has been some work on other formalisms of predictive representations in continuous systems (Wingate, 2008), these approaches have not yet been extended to a fully online, incremental setting.|Wingate, 2008	State abstraction in other predictive representation formalisms has been considered for both discrete (Wolfe et al., 2008) and continuous dynamical systems (Wingate, 2008).|Wingate, 2008	State abstraction in other predictive representation formalisms has been considered for both discrete (Wolfe et al., 2008) and continuous dynamical systems (Wingate, 2008).|Wolfe  et  al.,  2008
ddf1ea128fbc14a203c3b3d44d0135bb4dc33ffe	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|1	The resulting tensor formulation helped to analyze the mathematical structure of the problem and to derive its decomposition in the form of a 1-rank tensor decomposition known as Canonical Decomposition (CANDECOMP) [11,14,1,19].|1	The properties presented above distinguish our framework from one often used in the field of tensor decompositions [27,17,16,11,14,1,19], but do not limit its use for solving problems studied in that field.|1	Modeling of fluorescence data [1]|[1]	Social Network Analysis [1]|[1]	Any arbitrary tensor can be represented as a weighted sum of decomposed tensors [11, 1, 19, 15].|1	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|2	Computational problems with tensor structure, which involve large amounts of multidimensional data, arise in many fields of science and engineering [3, 8, 21, 4, 18, 14].|3	Fig. 4.4 compares visually how AMG and TMG are applied to a problem of reconstruction of a twodimensional image from a few arbitrarily taken samples, using non-uniform spline interpolation [3].|[3]	Our framework was successfully applied to solve a large real-world computational problem - a spline-based global variational reconstruction [3] of a multidimensional signal from incomplete and spatially scattered measurements in four dimensions.|[3]	Our approach does not require explicit storage either of the system tensor or its decomposition, and thus the problem of size, discussed above (33’554’432 unknowns parameters), for about 9’000’000 measurements, can be computed on current inexpensive multi core computer equipped with only 2 GBytes of physical memory in less than 60 minutes, surpassing the capability of a published, matrix-based solving algorithm [3] for the same problem by far.|[3]	Least squares problems [3, 21]|3	Computational problems with tensor structure, which involve large amounts of multidimensional data, arise in many fields of science and engineering [3, 8, 21, 4, 18, 14].|4	Some aspects of such automated code generation have also been discussed in [4].|[4]	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|5	Vectorization of multidimensional objects may lead to loss of spatial data coherence [6,13], which can adversely affect the performance of solving algorithms.|6	Independent Component Analysis [6, 15]|6	In our framework, multidimensional data and multidimensional transformations are described based on a formalism originating in Tensor Analysis [12] and Physics [7].|[7]	Computational problems with tensor structure, which involve large amounts of multidimensional data, arise in many fields of science and engineering [3, 8, 21, 4, 18, 14].|8	Integral equations [8]|[8]	Differential equations (Poisson, Navier-Stokes, Finite Element Methods) [18, 9]|9	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|10	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|11	The resulting tensor formulation helped to analyze the mathematical structure of the problem and to derive its decomposition in the form of a 1-rank tensor decomposition known as Canonical Decomposition (CANDECOMP) [11,14,1,19].|11	The properties presented above distinguish our framework from one often used in the field of tensor decompositions [27,17,16,11,14,1,19], but do not limit its use for solving problems studied in that field.|11	Any arbitrary tensor can be represented as a weighted sum of decomposed tensors [11, 1, 19, 15].|11	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|[12]	In our framework, multidimensional data and multidimensional transformations are described based on a formalism originating in Tensor Analysis [12] and Physics [7].|[12]	Vectorization of multidimensional objects may lead to loss of spatial data coherence [6,13], which can adversely affect the performance of solving algorithms.|13	Data compression [13]|[13]	Computational problems with tensor structure, which involve large amounts of multidimensional data, arise in many fields of science and engineering [3, 8, 21, 4, 18, 14].|14	Introduced in Tensor Analysis and Multilinear Algebra, tensors gained the attention of practitioners of diverse fields (see the excellent review by Kolda [14]).|[14]	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|14	The resulting tensor formulation helped to analyze the mathematical structure of the problem and to derive its decomposition in the form of a 1-rank tensor decomposition known as Canonical Decomposition (CANDECOMP) [11,14,1,19].|14	The properties presented above distinguish our framework from one often used in the field of tensor decompositions [27,17,16,11,14,1,19], but do not limit its use for solving problems studied in that field.|14	Independent Component Analysis [6, 15]|15	Any arbitrary tensor can be represented as a weighted sum of decomposed tensors [11, 1, 19, 15].|15	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|16	The properties presented above distinguish our framework from one often used in the field of tensor decompositions [27,17,16,11,14,1,19], but do not limit its use for solving problems studied in that field.|16	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|17	The properties presented above distinguish our framework from one often used in the field of tensor decompositions [27,17,16,11,14,1,19], but do not limit its use for solving problems studied in that field.|17	This definition is compatible with, and extends [17, 21].|17	Computational problems with tensor structure, which involve large amounts of multidimensional data, arise in many fields of science and engineering [3, 8, 21, 4, 18, 14].|18	Differential equations (Poisson, Navier-Stokes, Finite Element Methods) [18, 9]|18	However, translating tensor mathematics to a convenient computational framework raises many issues [19]; including, convenient notation, ease of algorithm implementation, performance.|[19]	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|19	The resulting tensor formulation helped to analyze the mathematical structure of the problem and to derive its decomposition in the form of a 1-rank tensor decomposition known as Canonical Decomposition (CANDECOMP) [11,14,1,19].|19	The properties presented above distinguish our framework from one often used in the field of tensor decompositions [27,17,16,11,14,1,19], but do not limit its use for solving problems studied in that field.|19	Any arbitrary tensor can be represented as a weighted sum of decomposed tensors [11, 1, 19, 15].|19	The resulting formulation is no longer explicitly multidimensional, - a fact that may create difficulty in identifying and understanding important properties inherent to the particular problem [20].|[20]	Signal filtering [20]|[20]	Computational problems with tensor structure, which involve large amounts of multidimensional data, arise in many fields of science and engineering [3, 8, 21, 4, 18, 14].|21	Least squares problems [3, 21]|21	This definition is compatible with, and extends [17, 21].|21	Modeling of electronic and optical properties of molecules and their interactions [25, 22]|22	Another type of iterative algorithms which are frequently used for solving large inverse problems, is the family of Krylov subspace solvers, which includes GMRES, CG, BICGSTAB and other solvers [23].|23	Pattern recognition [24, 28]|24	Modeling of electronic and optical properties of molecules and their interactions [25, 22]|25	This operation is a tensor analogue of the Khatri-Rao product [26] which is a matching elementwise (over i) Kronecker product of two sets of vectors.|[26]	The proposed framework is based on a generalization of the concepts of matrix algebra to multiple dimensions; it incorporates and unifies existing approaches from multidimensional signal processing [5,10,2] , recent developments in the field of tensor analysis [12], and multilinear algebra [27,17,16,11, 14,1,19].|27	The properties presented above distinguish our framework from one often used in the field of tensor decompositions [27,17,16,11,14,1,19], but do not limit its use for solving problems studied in that field.|27	Pattern recognition [24, 28]|28
563288fa9a74dbe18a45e8651aa9a3a256d4ff7c	In particular we obtain [9, Theorem 3.1] without appealing to the classification of all extremal codes of length 36 in [1].|[1]	The polynomial B(x, y) is anti-invariant under the MacWilliams transformation H: (x, y)7→1/√2(x+y, x−y) and invariant under the transformation I: (x, y)7→(x,−y), so by [2, Lemma 3.2] B(x, y)∈(x4−6x2y2+y4)·C[x2+y2, x2y2(x2−y2)2].|2	By [3], 2d(F) +d(S(F))≤4 +n2.|[3]	The research in this paper is part of the PhD thesis [4] of the first author.|[4]	A series of many papers has shown that if such a code exists, then its automorphism group Aut(C) ={σ∈S24m|σ(C) =C} has order ≤5 (see [4] for an exposition of this result).|[4]	It is shown in [9] and [5] that the code C is a free F2hσi-module, if and only if π(C(σ))is self-dual.|[5]	Stefka Bouyuklieva [6] studies automorphisms of order 2 of such codes|[6]	By direct calculations with Magma, using a database [8] of all self-dual binary linear codes of length up to 40, we get the following.|[8]	It is shown in [9] and [5] that the code C is a free F2hσi-module, if and only if π(C(σ))is self-dual.|[9]	In particular we obtain [9, Theorem 3.1] without appealing to the classification of all extremal codes of length 36 in [1].|9	Applying the methods from [10], we show the following main theorem|[10]	Then C is doubly even ([10]).|[10]	From the bound on d(Ci) given in [10, Theorem 5] we obtain dd(D) =d(D⊥)≤d(C1)≤4μ+ 6 if n≡22 (mod 24)4μ+ 4 otherwise|10	Since g(0) = 0 and g′(0)6= 0, we can apply Bürmann-Lagrange theorem (see [10, Lemma 8]) to obtain γh,k= [coeff. ofZh−kin(1−Z)−1−2⌊N−24⌋+2h] =2⌊N−24⌋ −h−kh−k>0.|10	Since g(0) = 0 and g′(0)6= 0, we can apply Bürmann-Lagrange theorem, in the version of [10, Lemma 8], to compute αi(N) =coeff. ofYiinY g′(Y)g(Y)f(Y)Yg(Y)i=:⋆|10	It is an intensively studied open question raised in [11], whether anextremal code of length 72 exists.|[11]
